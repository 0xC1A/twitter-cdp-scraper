#!/usr/bin/env python3
"""
Twitter æ¨æ–‡å¯¼å‡ºå·¥å…·
å°†å·²æŠ“å–çš„æ•°æ®è½¬æ¢ä¸ºå¤šç§æ ¼å¼
"""

import json
from pathlib import Path
from datetime import datetime

def load_tweets(username):
    """åŠ è½½å·²æŠ“å–çš„æ¨æ–‡æ•°æ®"""
    data_dir = Path(f'twitter_archives/{username}')
    
    # å°è¯•åŠ è½½åˆå¹¶åçš„æ–‡ä»¶
    all_tweets_file = data_dir / f'{username}_ALL_TWEETS.json'
    if all_tweets_file.exists():
        with open(all_tweets_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('tweets', [])
    
    # å°è¯•åŠ è½½ç®€å•æ–‡ä»¶
    simple_file = data_dir / f'{username}_SIMPLE.json'
    if simple_file.exists():
        with open(simple_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('tweets', [])
    
    # ä»åˆ†é¡µæ–‡ä»¶åˆå¹¶
    tweets = []
    seen_ids = set()
    
    for page_file in sorted(data_dir.glob('page_*.json')):
        with open(page_file, 'r', encoding='utf-8') as f:
            content = f.read()
            # æ‰¾åˆ° JSON å¼€å§‹
            lines = content.split('\n')
            json_start = 0
            for i, line in enumerate(lines):
                if line.strip().startswith('[') or line.strip().startswith('{'):
                    json_start = i
                    break
            try:
                data = json.loads('\n'.join(lines[json_start:]))
                if isinstance(data, list):
                    page_tweets = data
                else:
                    page_tweets = data.get('tweets', [])
                
                for t in page_tweets:
                    if isinstance(t, dict):
                        tid = t.get('id')
                        if tid and tid not in seen_ids:
                            seen_ids.add(tid)
                            tweets.append(t)
            except:
                pass
    
    return tweets

def export_to_markdown(tweets, username, output_file):
    """å¯¼å‡ºä¸º Markdown æ ¼å¼"""
    tweets.sort(key=lambda x: x.get('createdAt', ''), reverse=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# @{username} çš„æ¨æ–‡å­˜æ¡£\n\n")
        f.write(f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # ç»Ÿè®¡
        total = len(tweets)
        original = sum(1 for t in tweets if not t.get('inReplyToStatusId'))
        replies = sum(1 for t in tweets if t.get('inReplyToStatusId'))
        with_media = sum(1 for t in tweets if t.get('media'))
        
        f.write(f"## ç»Ÿè®¡\n\n")
        f.write(f"- æ€»è®¡: {total} æ¡\n")
        f.write(f"- åŸåˆ›: {original} æ¡\n")
        f.write(f"- å›å¤: {replies} æ¡\n")
        f.write(f"- å¸¦åª’ä½“: {with_media} æ¡\n\n")
        f.write("---\n\n")
        
        # æ¨æ–‡åˆ—è¡¨
        for t in tweets:
            date = t.get('createdAt', '')[:10] if t.get('createdAt') else 'æœªçŸ¥'
            text = t.get('text', '').strip()
            tweet_id = t.get('id', '')
            url = f"https://x.com/{username}/status/{tweet_id}"
            
            # äº’åŠ¨æ•°æ®
            likes = t.get('likeCount', 0)
            replies_count = t.get('replyCount', 0)
            retweets = t.get('retweetCount', 0)
            
            # æ ‡è®°
            is_reply = 'ğŸ’¬' if t.get('inReplyToStatusId') else 'ğŸ“'
            has_media = 'ğŸ“' if t.get('media') else ''
            
            f.write(f"### {is_reply} {has_media} [{date}]({url})\n\n")
            
            # æ¨æ–‡å†…å®¹
            for line in text.split('\n'):
                f.write(f"> {line}\n")
            
            f.write(f"\n")
            f.write(f"ğŸ‘ {likes}  ğŸ’¬ {replies_count}  ğŸ”„ {retweets}\n\n")
            
            # å¼•ç”¨çš„æ¨æ–‡
            if t.get('quotedTweet'):
                qt = t['quotedTweet']
                qt_author = qt.get('author', {}).get('username', 'unknown')
                qt_text = qt.get('text', '')[:100]
                f.write(f"> ğŸ’¬ å¼•ç”¨ [@{qt_author}](https://x.com/{qt_author}): {qt_text}...\n\n")
            
            f.write("---\n\n")
    
    print(f"âœ… Markdown: {output_file}")

def export_to_csv(tweets, username, output_file):
    """å¯¼å‡ºä¸º CSV æ ¼å¼"""
    import csv
    
    tweets.sort(key=lambda x: x.get('createdAt', ''), reverse=True)
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow([
            'ID', 'Date', 'Text', 'URL', 'Is Reply', 
            'Likes', 'Replies', 'Retweets', 'Has Media'
        ])
        
        for t in tweets:
            writer.writerow([
                t.get('id', ''),
                t.get('createdAt', ''),
                t.get('text', '').replace('\n', ' '),
                f"https://x.com/{username}/status/{t.get('id', '')}",
                'Yes' if t.get('inReplyToStatusId') else 'No',
                t.get('likeCount', 0),
                t.get('replyCount', 0),
                t.get('retweetCount', 0),
                'Yes' if t.get('media') else 'No'
            ])
    
    print(f"âœ… CSV: {output_file}")

def export_to_txt(tweets, username, output_file):
    """å¯¼å‡ºä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
    tweets.sort(key=lambda x: x.get('createdAt', ''), reverse=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"@{username} çš„æ¨æ–‡å­˜æ¡£\n")
        f.write(f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»è®¡: {len(tweets)} æ¡æ¨æ–‡\n")
        f.write("=" * 60 + "\n\n")
        
        for i, t in enumerate(tweets, 1):
            date = t.get('createdAt', '')[:10] if t.get('createdAt') else 'æœªçŸ¥'
            text = t.get('text', '')
            url = f"https://x.com/{username}/status/{t.get('id', '')}"
            
            f.write(f"[{i}] {date}\n")
            f.write(f"{text}\n")
            f.write(f"é“¾æ¥: {url}\n")
            f.write(f"ğŸ‘ {t.get('likeCount', 0)}  ğŸ’¬ {t.get('replyCount', 0)}\n")
            f.write("-" * 60 + "\n\n")
    
    print(f"âœ… TXT: {output_file}")

def export_summary(tweets, username, output_file):
    """å¯¼å‡ºæ‘˜è¦ç»Ÿè®¡"""
    from collections import Counter
    
    # ç»Ÿè®¡
    total = len(tweets)
    original = sum(1 for t in tweets if not t.get('inReplyToStatusId'))
    replies = sum(1 for t in tweets if t.get('inReplyToStatusId'))
    with_media = sum(1 for t in tweets if t.get('media'))
    
    total_likes = sum(t.get('likeCount', 0) for t in tweets)
    total_replies = sum(t.get('replyCount', 0) for t in tweets)
    total_retweets = sum(t.get('retweetCount', 0) for t in tweets)
    
    # æŒ‰æœˆä»½ç»Ÿè®¡
    months = Counter()
    for t in tweets:
        date = t.get('createdAt', '')
        if date:
            month = date[:7]  # YYYY-MM
            months[month] += 1
    
    # çƒ­é—¨æ¨æ–‡
    top_liked = sorted(tweets, key=lambda x: x.get('likeCount', 0), reverse=True)[:5]
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# @{username} æ¨æ–‡ç»Ÿè®¡æŠ¥å‘Š\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## æ€»ä½“ç»Ÿè®¡\n\n")
        f.write(f"- æ€»æ¨æ–‡æ•°: {total}\n")
        f.write(f"- åŸåˆ›æ¨æ–‡: {original}\n")
        f.write(f"- å›å¤: {replies}\n")
        f.write(f"- å¸¦åª’ä½“: {with_media}\n")
        f.write(f"- æ€»ç‚¹èµ: {total_likes}\n")
        f.write(f"- æ€»å›å¤: {total_replies}\n")
        f.write(f"- æ€»è½¬å‘: {total_retweets}\n\n")
        
        f.write("## æŒ‰æœˆåˆ†å¸ƒ\n\n")
        for month, count in sorted(months.items(), reverse=True):
            f.write(f"- {month}: {count} æ¡\n")
        
        f.write("\n## çƒ­é—¨æ¨æ–‡ (Top 5)\n\n")
        for i, t in enumerate(top_liked, 1):
            text = t.get('text', '')[:80]
            likes = t.get('likeCount', 0)
            url = f"https://x.com/{username}/status/{t.get('id', '')}"
            f.write(f"{i}. ğŸ‘ {likes} - {text}...\n")
            f.write(f"   {url}\n\n")
    
    print(f"âœ… ç»Ÿè®¡æŠ¥å‘Š: {output_file}")

def main():
    import sys
    
    username = sys.argv[1] if len(sys.argv) > 1 else 'lijigang'
    username = username.lstrip('@')
    
    print("=" * 60)
    print(f"Twitter æ¨æ–‡å¯¼å‡ºå·¥å…· - @{username}")
    print("=" * 60)
    
    # åŠ è½½æ¨æ–‡
    print(f"\nğŸ“‚ åŠ è½½æ¨æ–‡æ•°æ®...")
    tweets = load_tweets(username)
    
    if not tweets:
        print(f"âŒ æœªæ‰¾åˆ° @{username} çš„æ¨æ–‡æ•°æ®")
        print(f"è¯·ç¡®ä¿ twitter_archives/{username}/ ç›®å½•å­˜åœ¨æ•°æ®æ–‡ä»¶")
        return
    
    print(f"âœ“ åŠ è½½äº† {len(tweets)} æ¡æ¨æ–‡")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(f'twitter_exports/{username}')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # å¯¼å‡ºå„ç§æ ¼å¼
    print(f"\nğŸ“ å¯¼å‡ºä¸­...")
    export_to_markdown(tweets, username, output_dir / f'{username}_{timestamp}.md')
    export_to_csv(tweets, username, output_dir / f'{username}_{timestamp}.csv')
    export_to_txt(tweets, username, output_dir / f'{username}_{timestamp}.txt')
    export_summary(tweets, username, output_dir / f'{username}_{timestamp}_summary.md')
    
    print(f"\nâœ… å…¨éƒ¨å¯¼å‡ºå®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}/")
    
    # æ˜¾ç¤ºé¢„è§ˆ
    print(f"\nğŸ“ æœ€æ–° 5 æ¡æ¨æ–‡:")
    tweets.sort(key=lambda x: x.get('createdAt', ''), reverse=True)
    for t in tweets[:5]:
        date = t.get('createdAt', '')[:10] if t.get('createdAt') else 'æœªçŸ¥'
        text = t.get('text', '')[:50]
        reply_mark = 'ğŸ’¬' if t.get('inReplyToStatusId') else 'ğŸ“'
        print(f"  {reply_mark} [{date}] {text}...")

if __name__ == '__main__':
    main()
